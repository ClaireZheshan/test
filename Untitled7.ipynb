{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "from sets import Set\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "outmatr=defaultdict(set)\n",
    "inmatr=defaultdict(set)\n",
    "uniqueIds=defaultdict()\n",
    "groupmap = defaultdict(set)\n",
    "\n",
    "#Read the json file, parse it line by line and calculate tf-idf values to populate dictionary\n",
    "def readFl(jsonfile):    \n",
    "    data=[]\n",
    "    with open(jsonfile,'r') as json_file:    \n",
    "        for line in json_file:\n",
    "            data.append(json.loads(line))\n",
    "    grpcnt=0;\n",
    "    for field in data:                                \n",
    "            uniqueIds[field[\"user\"][\"id\"]]=field[\"user\"][\"screen_name\"]    \n",
    "            groupmap[grpcnt%4].add(field[\"user\"][\"id\"])\n",
    "            grpcnt+=1                   \n",
    "            if 'user_mentions' in field[\"entities\"]:\n",
    "                if field[\"entities\"][\"user_mentions\"]:                                    \n",
    "                    for dt in field[\"entities\"][\"user_mentions\"]:                                                                                              \n",
    "                        if(field[\"user\"][\"id\"]!=dt[\"id\"]):\n",
    "                            uniqueIds[dt[\"id\"]]=dt[\"screen_name\"]                            \n",
    "                            inmatr[dt[\"id\"]].add(field[\"user\"][\"id\"])\n",
    "                            outmatr[field[\"user\"][\"id\"]].add(dt[\"id\"])\n",
    "                            if dt[\"id\"] not in outmatr:\n",
    "                                outmatr[dt[\"id\"]]=Set()\n",
    "                            if field[\"user\"][\"id\"] not in inmatr:\n",
    "                                inmatr[field[\"user\"][\"id\"]]=Set()\n",
    "\n",
    "    for key,val in groupmap.iteritems():                                                \n",
    "        ranklst=calcPgRank(key)\n",
    "        newdict=OrderedDict(sorted(ranklst.items(), key=lambda t: t[1],reverse=True)[:10])\n",
    "        print \"\\n Group: \", key, \"\\n\"          \n",
    "        rank=0\n",
    "        for node,val in newdict.iteritems():\n",
    "            print \"rank: \",rank,\"name: \",uniqueIds[node].encode('utf-8'),\"node: \",node,\"val: \",val\n",
    "            rank+=1                                  \n",
    "    return\n",
    "\n",
    "#calculate rank value of every user. If dangling user, rank should be zero. \n",
    "#Uses the linear method for calculating pagerank\n",
    "def calcPgRank(grp):\n",
    "    alpha=0.1\n",
    "    ranklist=defaultdict(lambda: 0.0000)\n",
    "    currlist=defaultdict(lambda: 0.0000)\n",
    "    \n",
    "    for node,name in uniqueIds.iteritems():\n",
    "        if node in inmatr and node in groupmap[grp]:                      \n",
    "            ranklist[node]=1.0000/len(inmatr)\n",
    "                                   \n",
    "    while(1):                         \n",
    "        flag=0                \n",
    "        for node,name in uniqueIds.iteritems():\n",
    "          if node in groupmap[grp]:            \n",
    "            currlist[node]            \n",
    "            if node in inmatr:                                   \n",
    "                currlist[node]=alpha                \n",
    "                for innode in inmatr[node]:\n",
    "                    if innode in groupmap[grp]:\n",
    "                        outcnt=0                                          \n",
    "                        for nd in outmatr[innode]:\n",
    "                            if nd in groupmap[grp]:\n",
    "                                outcnt+=1\n",
    "                        currlist[node]+=((1-alpha)*(ranklist[innode]/outcnt))            \n",
    "                if (math.fabs(currlist[node]-ranklist[node])>0.0001):                       \n",
    "                    flag=1                                                                         \n",
    "        ranklist=currlist.copy()                        \n",
    "        if(flag==0):\n",
    "            break        \n",
    "    return currlist                                           \n",
    "\n",
    "#Main function that calls the function to process the json file\n",
    "def main():\n",
    "    readFl('mars_tweets_medium.json')\n",
    "    print \"END\"\n",
    "    return\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pygraph.classes.digraph import digraph\n",
    "\n",
    "\n",
    "class PRIterator:\n",
    "    __doc__ = '''计算一张图中的PR值'''\n",
    "\n",
    "    def __init__(self, dg):\n",
    "        self.damping_factor = 0.85  # 阻尼系数,即α\n",
    "        self.max_iterations = 100  # 最大迭代次数\n",
    "        self.min_delta = 0.00001  # 确定迭代是否结束的参数,即ϵ\n",
    "        self.graph = dg\n",
    "\n",
    "    def page_rank(self):\n",
    "        #  先将图中没有出链的节点改为对所有节点都有出链\n",
    "        for node in self.graph.nodes():\n",
    "            if len(self.graph.neighbors(node)) == 0:\n",
    "                for node2 in self.graph.nodes():\n",
    "                    digraph.add_edge(self.graph, (node, node2))\n",
    "\n",
    "        nodes = self.graph.nodes()\n",
    "        graph_size = len(nodes)\n",
    "\n",
    "        if graph_size == 0:\n",
    "            return {}\n",
    "        page_rank = dict.fromkeys(nodes, 1.0 / graph_size)  # 给每个节点赋予初始的PR值，利用fromkeys函数将后面的值赋予前面的键，建立新字典\n",
    "        damping_value = (1.0 - self.damping_factor) / graph_size  # 公式中的(1−α)/N部分\n",
    "\n",
    "        flag = False\n",
    "        for i in range(self.max_iterations):\n",
    "            change = 0\n",
    "            for node in nodes:\n",
    "                rank = 0\n",
    "                for incident_page in self.graph.incidents(node):  # 遍历所有“入射”的页面\n",
    "                    rank += self.damping_factor * (page_rank[incident_page] / len(self.graph.neighbors(incident_page)))\n",
    "                rank += damping_value\n",
    "                change += abs(page_rank[node] - rank)  # 绝对值，PageRank的变化量？\n",
    "                page_rank[node] = rank\n",
    "\n",
    "            print(\"This is NO.%s iteration\" % (i + 1))\n",
    "            print(page_rank)\n",
    "\n",
    "            if change < self.min_delta:  #变化量小于error\n",
    "                flag = True\n",
    "                break\n",
    "        if flag:\n",
    "            print(\"finished in %s iterations!\" % node)\n",
    "        else:\n",
    "            print(\"finished out of 100 iterations!\")\n",
    "        return page_rank\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dg = digraph()\n",
    "\n",
    "    dg.add_nodes([\"A\", \"B\", \"C\", \"D\", \"E\"])\n",
    "\n",
    "    dg.add_edge((\"A\", \"B\"))\n",
    "    dg.add_edge((\"A\", \"C\"))\n",
    "    dg.add_edge((\"A\", \"D\"))\n",
    "    dg.add_edge((\"B\", \"D\"))\n",
    "    dg.add_edge((\"C\", \"E\"))\n",
    "    dg.add_edge((\"D\", \"E\"))\n",
    "    dg.add_edge((\"B\", \"E\"))\n",
    "    dg.add_edge((\"E\", \"A\"))\n",
    "\n",
    "    pr = PRIterator(dg)\n",
    "    page_ranks = pr.page_rank()\n",
    "\n",
    "    print(\"The final page rank is\\n\", page_ranks)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

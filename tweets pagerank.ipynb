{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'mars_tweets_medium.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-67068a35822d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-67068a35822d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGINT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignal_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mreadFl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mars_tweets_medium.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0mstr1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter search query \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-67068a35822d>\u001b[0m in \u001b[0;36mreadFl\u001b[0;34m(jsonfile)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjsonfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'mars_tweets_medium.json'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python -tt\n",
    "#The json file must be present in the same directory as this python script\n",
    "#\"工作马马虎虎，只想在兴趣和游戏中寻觅快活，充其量只能获得一时的快感，\n",
    "#绝不能尝到从心底涌出的惊喜和快乐，但来自工作的喜悦并不像糖果那样—放进嘴里就甜味十足，而是需要从苦劳与艰辛中渗出，因此当我们聚精会神，\n",
    "#孜孜不倦，克服艰辛后的成就感，世上没有哪种喜悦可以类比”\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "import signal\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "\n",
    "#Global Dictionaries to store tf, idf, tf-idf values\n",
    "tf = defaultdict(lambda: defaultdict(float))\n",
    "idf = defaultdict(float)\n",
    "logidf = defaultdict(float)\n",
    "tfidf = defaultdict(lambda: defaultdict(float))\n",
    "#Dictionary to store tweets with line number/json object number as the key\n",
    "tweets=defaultdict()\n",
    "#Dictionary to store tweet id with line number/json object number as the key\n",
    "id=defaultdict()\n",
    "\n",
    "#Read the json file, parse it line by line and calculate tf-idf values to populate dictionary \n",
    "def readFl(jsonfile):  \n",
    "    data=[]      \n",
    "    index=0\n",
    "    with open(jsonfile,'r') as json_file:    \n",
    "        for line in json_file:\n",
    "            data.append(json.loads(line))    \n",
    "    for field in data:\n",
    "        tweets[index]=field[\"text\"]\n",
    "        id[index]=field[\"id\"]        \n",
    "        processData(field[\"text\"],index)\n",
    "        index=index+1               \n",
    "    for k,v in idf.iteritems():\n",
    "        n=index/v\n",
    "        idf[k]=math.log(n,2)    \n",
    "    for k,v in tf.iteritems(): \n",
    "        sum=0                                \n",
    "        for m,n in v.iteritems():                                    \n",
    "            tfidf[k][m]=(1+math.log(tf[k][m],2))*idf[m]\n",
    "            sum+=(tfidf[k][m])*(tfidf[k][m])\n",
    "        norm=math.sqrt(sum)            \n",
    "        for i,j in v.iteritems():\n",
    "            tfidf[k][i]=tfidf[k][i]/norm                                                                                                    \n",
    "    return\n",
    "\n",
    "#Calculates the tfidf value of the query and get the top 50 tweets that match the quesry based on the tf-idf value \n",
    "def processQuery(str):\n",
    "    qtf = defaultdict(float)\n",
    "    qtfidf = defaultdict(float)\n",
    "    sum=0    \n",
    "    qwords=re.findall('\\w+', str.lower(),re.UNICODE)\n",
    "    for word in qwords:\n",
    "        qtf[word]=qtf[word]+1;\n",
    "    for k,v in qtf.iteritems():\n",
    "        qtf[k]=(1+math.log(qtf[k],2))\n",
    "        qtfidf[k]=qtf[k]*idf[k]\n",
    "        if(qtfidf[k]==0):\n",
    "            print (\"no match\")\n",
    "            return\n",
    "        sum+=qtfidf[k]*qtfidf[k]    \n",
    "    norm=math.sqrt(sum)            \n",
    "    for i,j in qtfidf.iteritems():\n",
    "        qtfidf[i]=qtfidf[i]/norm\n",
    "    pgrank=buildRank(qtfidf)\n",
    "    newdict=OrderedDict()              \n",
    "    newdict=OrderedDict(sorted(pgrank.iteritems(), key=lambda t: t[1],reverse=True)[:50])\n",
    "    print (\"Tweet Rankings \\n\")\n",
    "    rank=1    \n",
    "    for key,val in newdict.iteritems():\n",
    "        if(newdict[key]!=0):\n",
    "            print (\"rank: \",rank, \"tweet id: \", id[key],\"tweet: \",tweets[key].encode('utf-8'))\n",
    "            rank+=1                                                    \n",
    "    return\n",
    "\n",
    "#Function that calculates the tf-idf value from each the tf and idf dictionaries\n",
    "def buildRank(qtidf):    \n",
    "    rank=defaultdict(float)\n",
    "    for k,v in tfidf.iteritems():          \n",
    "        for i,j in qtidf.iteritems():                        \n",
    "            rank[k]+=qtidf[i]*v[i]                   \n",
    "    return rank\n",
    "\n",
    "#Splits each tweet text into a set of unique words and updates the global tf and idf dictionary based on the word count. \n",
    "def processData(strng,index):\n",
    "    uniqueWords=Set()\n",
    "    parwords=re.findall('\\w+', strng.lower(),re.UNICODE)\n",
    "    for word in parwords:\n",
    "        tf[index][word]=tf[index][word]+1;\n",
    "        uniqueWords.add(word)  \n",
    "    for word in uniqueWords:\n",
    "        idf[word] = idf[word]+1   \n",
    "    return\n",
    "\n",
    "#handling ctrl+C interrupt to exit\n",
    "def signal_handler(signal, frame):\n",
    "    print ('\\nExiting. Bye')\n",
    "    sys.exit(0)\n",
    "\n",
    "#Main function that calls the function that processes the json file, inputs and processes the query repeatedly  \n",
    "def main():\n",
    "    signal.signal(signal.SIGINT, signal_handler)                \n",
    "    readFl('mars_tweets_medium.json')\n",
    "    str1 = raw_input(\"Enter search query \\n\")\n",
    "    while(1):        \n",
    "        processQuery(str1)\n",
    "        str1 = raw_input(\"Enter search query \\n\")\n",
    "    print (\"END\")\n",
    "    return\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
